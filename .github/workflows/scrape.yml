name: Scrape Sahi Buzz

on:
  schedule:
    - cron: '0 16 * * 5'  # Every 5 minutes (minimum GitHub allows)
  workflow_dispatch:       # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Chrome dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Node dependencies
        run: npm install puppeteer-core

      - name: Run scrape script
        run: node scrape.js

      - name: Commit updated output.json
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add output.json
          git commit -m "Update scraped data [bot]" || echo "No changes to commit"
          git push https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git HEAD:${{ github.ref }}

